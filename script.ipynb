{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Done by Nayan Man Singh Pradhan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import json\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.de.stop_words import STOP_WORDS\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from google_trans_new import google_translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standort Trovarit AG München, Deutschland</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wir freuen uns auf Ihre Bewerbung unter Angabe...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Qualifikation zur Heimleitung gemäß Heimperson...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gute organisatorische und konzeptionelle Fähig...</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teamfähigkeit, hohe Flexibilität und Einsatzbe...</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0          Standort Trovarit AG München, Deutschland  none\n",
       "1  Wir freuen uns auf Ihre Bewerbung unter Angabe...  none\n",
       "2  Qualifikation zur Heimleitung gemäß Heimperson...  tech\n",
       "3  Gute organisatorische und konzeptionelle Fähig...  soft\n",
       "4  Teamfähigkeit, hohe Flexibilität und Einsatzbe...  soft"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reading data\n",
    "df = pd.read_json('https://talentbait-assets.s3.eu-central-1.amazonaws.com/tech_soft_none.json')\n",
    "# df = pd.read_json('dataset.json')\n",
    "df = pd.json_normalize(df['data'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining names\n",
    "text = df['text']\n",
    "label = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none    4325\n",
      "soft    3635\n",
      "tech    2289\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## checking data\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "## visualizing\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "x_axis = [\"none\", \"soft\", \"tech\"]\n",
    "y_axis = [df[\"label\"].value_counts()[0],df[\"label\"].value_counts()[1],df[\"label\"].value_counts()[2]]\n",
    "ax.bar(x_axis, y_axis)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helpers for data cleaning\n",
    "punctuation = string.punctuation\n",
    "stop_words = list(STOP_WORDS)\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "numbers = string.digits\n",
    "# print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function that cleans input text\n",
    "def cleaning_function(input_text):\n",
    "    text = nlp(input_text)\n",
    "    tokens = []\n",
    "    for token in text:\n",
    "        temp = token.lemma_.lower()\n",
    "        tokens.append(temp)\n",
    "\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and token not in punctuation and token not in numbers:\n",
    "            cleaned_tokens.append(token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freuen', 'bewerbung', 'angabe', 'gehaltsvorstellung', 'eintrittstermins', 'alte', 'leipziger', '–', 'hallesche', 'konzern', 'begrüßen', 'ausdrücklich', 'bewerbung', 'mensch', 'behinderung', 'frage', 'information', 'wenden', 'gerne', 'elke', '0711', '6603', '2411', 'ausführlich', 'bewerbungsunterlagen', 'senden', 'bitte', 'bewerbung@hallesche.de', 'per', 'post', 'hallesche', 'krankenversicherung', 'a.', 'g.', 'personal', 'soziales', 'reinsburgstraße', '10', '70178', 'stuttgart', 'www.hallesche.de']\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "cleaned_text = cleaning_function(text[1])\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Data: Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## variables for train and test data\n",
    "X = text\n",
    "y = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SVC_score'></a>\n",
    "### SVC training and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.94      0.98      0.96      1337\n",
      "        soft       0.94      0.94      0.94      1068\n",
      "        tech       0.94      0.87      0.90       670\n",
      "\n",
      "    accuracy                           0.94      3075\n",
      "   macro avg       0.94      0.93      0.93      3075\n",
      "weighted avg       0.94      0.94      0.94      3075\n",
      "\n",
      "Confusion Matrix for SVC:\n",
      "[[1313   13   11]\n",
      " [  43 1000   25]\n",
      " [  43   46  581]]\n"
     ]
    }
   ],
   "source": [
    "## SVC using tfidf (bag of words)\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer = cleaning_function)\n",
    "classifier = LinearSVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=50)\n",
    "SVC_clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "y_pred = SVC_clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report for SVC:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix for SVC:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='KNN_score'></a>\n",
    "### KNN training and score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.65      0.99      0.79      1337\n",
      "        soft       0.96      0.70      0.81      1068\n",
      "        tech       0.95      0.37      0.53       670\n",
      "\n",
      "    accuracy                           0.75      3075\n",
      "   macro avg       0.85      0.69      0.71      3075\n",
      "weighted avg       0.82      0.75      0.74      3075\n",
      "\n",
      "Confusion Matrix for KNN:\n",
      "[[1326    8    3]\n",
      " [ 313  744   11]\n",
      " [ 394   27  249]]\n"
     ]
    }
   ],
   "source": [
    "## KNN using tfidf (bag of words)\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer = cleaning_function)\n",
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=50)\n",
    "\n",
    "KNN_clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\n",
    "KNN_clf.fit(X_train, y_train)\n",
    "y_pred = KNN_clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report for KNN:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix for KNN:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Bernoulli:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        none       0.99      0.73      0.84      1337\n",
      "        soft       0.66      0.99      0.79      1068\n",
      "        tech       0.98      0.71      0.83       670\n",
      "\n",
      "    accuracy                           0.82      3075\n",
      "   macro avg       0.88      0.81      0.82      3075\n",
      "weighted avg       0.87      0.82      0.82      3075\n",
      "\n",
      "Confusion Matrix for Bernoulli:\n",
      "[[ 972  362    3]\n",
      " [   6 1057    5]\n",
      " [   6  185  479]]\n"
     ]
    }
   ],
   "source": [
    "## BernoulliNB using tfidf (bag of words)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer = cleaning_function)\n",
    "classifier = BernoulliNB()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=50)\n",
    "Bernoulli_clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\n",
    "Bernoulli_clf.fit(X_train, y_train)\n",
    "y_pred = Bernoulli_clf.predict(X_test)\n",
    "\n",
    "print(\"Classification Report for Bernoulli:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix for Bernoulli:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Trained Model on User Input\n",
    "<a id='TTMUI'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your input in German: Good at communication\n",
      "Input language detected: english\n",
      "Translated to German: Gut in der Kommunikation \n",
      "\n",
      "\n",
      "Prediction via SVC: soft\n",
      "Prediction via KNN: soft\n",
      "Prediction via Bernoulli: soft\n"
     ]
    }
   ],
   "source": [
    "## predicting via user input\n",
    "\n",
    "user_input_text = input(\"Enter your input in German: \")\n",
    "\n",
    "## additional translation feature if input is not in German\n",
    "translator = google_translator()\n",
    "if(translator.detect(user_input_text)[0]!='de'):\n",
    "    print(\"Input language detected:\", translator.detect(user_input_text)[1])\n",
    "    in_german = translator.translate(user_input_text, lang_tgt='de')\n",
    "    print(\"Translated to German:\", in_german)\n",
    "    user_input_text = in_german\n",
    "\n",
    "svc_pred = SVC_clf.predict([user_input_text])\n",
    "knn_pred = KNN_clf.predict([user_input_text])\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print (\"Prediction via SVC:\", svc_pred[0])\n",
    "print (\"Prediction via KNN:\", knn_pred[0])\n",
    "\n",
    "# added later\n",
    "Bernoulli_pred = Bernoulli_clf.predict([user_input_text])\n",
    "print(\"Prediction via Bernoulli:\", Bernoulli_pred[0])\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing most Frequent Words for Different Labels after Cleaning Data\n",
    "<a id='VMFWDL'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0687f08ded60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclean_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tech\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-da61cb229d92>\u001b[0m in \u001b[0;36mcleaning_function\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## function that cleans input text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcleaning_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/spacy/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtok2vec\u001b[0m\u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtokvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mbatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok2VecListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlistener\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisteners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         return _ragged_forward(\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRagged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRagged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36m_ragged_forward\u001b[0;34m(model, Xr, is_train)\u001b[0m\n\u001b[1;32m     88\u001b[0m ) -> Tuple[Ragged, Callable]:\n\u001b[1;32m     89\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mArrayXd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArrayXd\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataXd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdYr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRagged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/thinc/layers/layernorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mXhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_begin_update_scale_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## splitting data based on label\n",
    "\n",
    "only_tech_tokens = []\n",
    "only_soft_tokens = []\n",
    "only_none_tokens = []\n",
    "\n",
    "for i in range(0, text.shape[0]):\n",
    "    clean_token = cleaning_function(text[i])\n",
    "    \n",
    "    if label[i] == \"tech\":\n",
    "        for t in clean_token:\n",
    "            only_tech_tokens.append(t)\n",
    "            \n",
    "    elif label[i] == \"soft\":\n",
    "        for t in clean_token:\n",
    "            only_soft_tokens.append(t)\n",
    "            \n",
    "    else:\n",
    "        for t in clean_token:\n",
    "            only_none_tokens.append(t)\n",
    "            \n",
    "freq_tech_tokens = nltk.FreqDist(only_tech_tokens)\n",
    "freq_soft_tokens = nltk.FreqDist(only_soft_tokens)\n",
    "freq_none_tokens = nltk.FreqDist(only_none_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent word in label: 'none'\n",
    "<a id='g_none'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most common words used in dataset of label none\n",
    "print(\"Visual representation of most common words used in dataset of label 'none'\")\n",
    "freq_none_tokens.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent word in label: 'tech'\n",
    "<a id='g_tech'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most common words used in dataset of label tech\n",
    "print(\"Visual representation of most common words used in dataset of label 'tech'\")\n",
    "freq_tech_tokens.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most frequent word in label: 'soft'\n",
    "<a id='g_soft'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most common words used in dataset of label soft\n",
    "print(\"Visual representation of most common words used in dataset of label 'soft'\")\n",
    "freq_soft_tokens.plot(30, cumulative=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "## anvil to host web application\n",
    "import anvil.server\n",
    "anvil.server.connect(\"I6ZCACWHQSGJRHKJKAK4CEPD-KDZYNHP6HUKJWUBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def predict_class(user_input):\n",
    "    translator = google_translator()\n",
    "    if(translator.detect(user_input)[0]!='de'):\n",
    "        user_input = translator.translate(user_input, lang_tgt='de')\n",
    "    return (SVC_clf.predict([user_input])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessible via:**\n",
    "https://KDZYNHP6HUKJWUBA.anvil.app/TYLJ73PI6MEOA76NVDBMX4JS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Application\n",
    "**Accessible via running:**\n",
    "_python3 application.py_\n",
    "**in terminal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaination of my Model and Approach\n",
    "\n",
    "My classification pipeline consists of a **tfidf element** and a **classifier element**.\n",
    "\n",
    "The tfidf element converts the sentences into tokens and cleans the input data. In order to clean the input data, I made a function that does the following:\n",
    "1. Convert the sentences into tokens\n",
    "2. Lemmatisation/Stemming of the tokens such that words like wir -> ich, bin -> sein etc belong to the same 'stem'\n",
    "3. Convert all alphabets into lower case alphabets\n",
    "4. Remove stop words like: weiter, solchen, zehntes\n",
    "5. Remove punctuations like: .,!\n",
    "\n",
    "After the data is cleaned, the tfidf (term frequency-inverse document frequency) is responsible of giving weights (importance) to words based on the logarithmic ratio of the number of documents to the document frequency of the word. That means, if a word is common in all three labels, the word is given less weight as compared to another word that is only present in one label.\n",
    "\n",
    "I tested the classifier element with two classifying algorithms: Linear SVC and KNN. I observed that the Linear SVC performed much better than the KNN, hence, I used the model from the Linear SVC for my web application and command line application. The Linear SVC model gave good and accurate results, hence, it is a good model for the dataset. The SVC is good for this task because the instance is of a very high dimension and the feature vectors are sparse, which makes differentiating areas for distinct feature space more accurate. The full classification report and confusion matrix for Linear SVC and KNN can be found here:\n",
    "\n",
    "[Linear SVC Score](#SVC_score)  \n",
    "[KNN Score](#KNN_score)\n",
    "\n",
    "After I got the classification report, I tested the model using my own input text (under [Testing Trained Model on User Input](#TTMUI)). I also added an **additional feature** which allows the user to input the text in any language supported by the 'google_trans_new' library (The list of supported languages can be found in [this](https://duyguaran.medium.com/how-to-use-google-trans-new-346ab827a4eb) article). The algorithm detects the input language and translates the text into German (if the detected text is not in German) and feeds the translated text into the pipeline in order to predict the label. This feature is also implemented in the Web Application and Command Line Application.\n",
    "\n",
    "In order to visualize the data, I made 3 additional graphs (under [Visualizing most Frequent Words for Different Labels](#VMFWDL) that graphs the 30 most frequent words in the x-axis and their count in the y-axis for the 3 different labesl: [none](#g_none), [tech](#g_tech), and [soft](#g_soft). This frequency data can be used to observe/visualize what tokens/words were the most common/weighted while classifying the data.\n",
    "\n",
    "The web application is hosted by Anvil. It can be accessed by connecting the the server and opening the link on any computer.\n",
    "\n",
    "The Command Line Application is made by using two files: 'pickle_dumper.py' and 'application.py'. 'pickle_dumper.py' is where the data is trained and dumped into the pickle file and the 'application.py' file is where the command prompt UI is made and prediciton is done. Only running 'python3 application.py' through terminal executes the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions\n",
    "- Maybe in the future, the dataset could have more than 3 labels such that the candidates can classify the skills in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
